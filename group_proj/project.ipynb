{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project - Cat Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 4: Isaiah Martinez, Joycelyn Tuazon\n",
    "## Mrs. Lord - Comp 542 Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes, Familiarization, and Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import projHelper as pjH\n",
    "\n",
    "extremeSizes = pjH.calculateExtremeSizes(\"animals_cleaned\")\n",
    "print(extremeSizes[0], \"\\tMaxWidth\")\n",
    "print(extremeSizes[1], \"\\tMinWidth\")\n",
    "print(extremeSizes[2], \"\\tMaxHeight\")\n",
    "print(extremeSizes[3], \"\\tMinHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for an image of size 500,500 within the cats folder\n",
    "\n",
    "matches = pjH.imgSizeMatch([500, 500], \"animals/cats/\")\n",
    "\n",
    "#there are none so we should see an empty list\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we're going to utilize keras for gaining insights into our images\n",
    "import keras\n",
    "\n",
    "img = keras.preprocessing.image.load_img(\"animals/cats/cats_00001.jpg\")\n",
    "#Notice the image from keras is of type PIL\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "\n",
    "#img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show how resizing the image selected works\n",
    "\n",
    "#notice this image has one dimension of size less than 500,500\n",
    "image = img.resize([500,500])\n",
    "#image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for an image of size 100, 87 within the panda folder\n",
    "\n",
    "matches = pjH.imgSizeMatch([100, 87], \"animals/panda/\")\n",
    "\n",
    "#there is exactly one\n",
    "print(matches)\n",
    "\n",
    "#Using the found filename, we will stretch the image out to 500,500 and see what happens when we resize it\n",
    "#notice this image has both dimensions of size less than 500,500\n",
    "\n",
    "img2 = keras.preprocessing.image.load_img(\"animals/panda/panda_00478.jpg\")\n",
    "#img2.show()\n",
    "\n",
    "image2 = img2.resize([500,500])\n",
    "#image2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for an image of size 1600, 1200 within the panda folder\n",
    "\n",
    "matches = pjH.imgSizeMatch([1600, 1200], \"animals/panda/\")\n",
    "\n",
    "#there is exactly one\n",
    "print(matches)\n",
    "\n",
    "#Using the found filename, we will stretch the image out to see what happens when we resize it\n",
    "#notice this image has both dimensions of size greater than 500,500\n",
    "\n",
    "img3 = keras.preprocessing.image.load_img(\"animals/panda/panda_00880.jpg\")\n",
    "#img3.show()\n",
    "\n",
    "image3 = img3.resize([500,500])\n",
    "#image3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Avg dimensions of all images\n",
    "avgDims = pjH.avgDims(\"animals_cleaned\")\n",
    "print(avgDims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image3Array = np.asarray(image3)\n",
    "print(image3Array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guides that may provide insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count objects\n",
    "#https://new.pythonforengineers.com/blog/image-and-video-processing-in-python/\n",
    "\n",
    "#Basic outline for image classificaiton. See youtube video too.\n",
    "#https://www.youtube.com/watch?v=il8dMDlXrIE\n",
    "#https://github.com/computervisioneng/image-classification-python-scikit-learn/blob/master/main.py\n",
    "\n",
    "#Image classification with Tensorflow and Keras\n",
    "#https://www.tensorflow.org/tutorials/images/classification\n",
    "\n",
    "#Load and Preprocess Images\n",
    "#https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Examples with Code to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good to model after\n",
    "# Also in the Conv2D section\n",
    "# https://www.kaggle.com/code/shaileshkakade/image-classification-cat-dog-panda\n",
    "\n",
    "# plots vertical/horizontal edge detection\n",
    "# https://www.kaggle.com/code/dianalaveena/cnn-keras-image-classification\n",
    "# Consider KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/dongduongminh/cnn-deep-learning-image-classification\n",
    "# https://www.kaggle.com/code/nasrinjahanripa/animal-images-classification-cnn\n",
    "# https://www.kaggle.com/code/corneliustantius/classification-with-keras-cnn\n",
    "# SEE `explaining-line.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/chenjiarui2018/cats-dogs-and-pandas-convnext#3.-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/arpita12/cat-dog-panda\n",
    "# https://www.kaggle.com/code/rwt1998/animal-classification\n",
    "# https://www.kaggle.com/code/atmaraiprince/animal-image-dataset\n",
    "# https://www.kaggle.com/code/kkamal2003/animal-images-cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/shaileshkakade/image-classification-cat-dog-panda\n",
    "# https://www.kaggle.com/code/etienne1976/animal-image-classification-with-keras\n",
    "# https://www.kaggle.com/code/bygbrains/dog-cat-pandas-image-classifier\n",
    "# https://www.kaggle.com/code/dianalaveena/cnn-keras-image-classification#5.-Model-Building-and-Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res Net 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/nasrinjahanripa/animal-images-classification-cnn\n",
    "# https://www.kaggle.com/code/profmedo/image-classification-cnn-with-resnet\n",
    "# https://www.kaggle.com/code/kkamal2003/resnet-for-classification\n",
    "# https://www.kaggle.com/code/arshnoor7389/resnet-for-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI - CLIP\n",
    "## Dont use CLIP as project. CLIP may provide insight or be compared to, but not submitted for grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GITHUB LINK:\n",
    "# https://github.com/openai/CLIP/blob/main/model-card.md#model-card-clip\n",
    "# https://www.kaggle.com/code/kimchanyoung/zero-shot-prediction-using-openai-s-clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Code applying the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following the Loading and Preprocessing Tensorflow tutorial from the above code\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 500\n",
    "img_width = 500\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  directory=\"animals_cleaned/\",\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "#3 classes are cat/dog/panda\n",
    "#2362 ~~ 2361.6 = 2952 * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from PIL import Image as im\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train[0])\n",
    "\n",
    "img4 = im.fromarray(X_train[0])\n",
    "\n",
    "#img4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize all images into arrays\n",
    "\n",
    "cats_resized = pjH.getResizedFlattenedArrays(\"animals_cleaned/cats/\")\n",
    "dogs_resized = pjH.getResizedFlattenedArrays(\"animals_cleaned/dogs/\")\n",
    "panda_resized = pjH.getResizedFlattenedArrays(\"animals_cleaned/panda/\")\n",
    "\n",
    "#each image is an array of 750,000 (500 * 500 * 3)\n",
    "print(cats_resized[0])\n",
    "print(cats_resized[0].shape)\n",
    "\n",
    "#Resized cat/dog/panda images into a single array of size 994/990/968\n",
    "print(\"# cat imgs\", len(cats_resized))\n",
    "print(\"# dog imgs\", len(dogs_resized))\n",
    "print(\"# panda imgs\", len(panda_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labels and combine data into a single array\n",
    "\n",
    "#insert labels into array\n",
    "labels = [\"cat\"] * len(cats_resized) + [\"dog\"] * len(dogs_resized) + [\"panda\"] * len(panda_resized)\n",
    "\n",
    "#combine data into a single array\n",
    "data_resized = [*cats_resized, *dogs_resized, *panda_resized]\n",
    "\n",
    "#compare sizes of labels and data_resized since they should be the same\n",
    "#expected: True\n",
    "print(len(data_resized) == len(labels))\n",
    "\n",
    "#testing labels\n",
    "#expected: cat cat dog dog panda panda\n",
    "print(labels[0], labels[993], labels[994], labels[1983], labels[1984], labels[2951])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert all data (data_resized and labels) into a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data_resized)\n",
    "\n",
    "df['animal'] = labels\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train/Test (80/20)\n",
    "#Note: This is an example train/test split, you might want to change the split to improve model performance\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, train_size = 0.8, shuffle = True)\n",
    "\n",
    "#xTrain, yTrain: Used for training\n",
    "#xTest,  yTest:  Used for testing \n",
    "\n",
    "print(xTrain.head(), \"\\n\")\n",
    "print(yTrain.head(), \"\\n\")\n",
    "print(xTest.head(), \"\\n\")\n",
    "print(yTest.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(xTrain), type(xTest), type(yTrain), type(yTest))\n",
    "\n",
    "yTrain = pd.DataFrame(yTrain).values.ravel()\n",
    "yTest = pd.DataFrame(yTest).values.ravel()\n",
    "\n",
    "print(type(xTrain), type(xTest), type(yTrain), type(yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#                       Notes                           #\n",
    "#########################################################\n",
    "\n",
    "# print out Accuracy, Specificity, Recall, F1 Score. If possible, also the Confusion Matrix\n",
    "\n",
    "# Analyze model for Over/Underfitting so that it can be reduced\n",
    "\n",
    "# Use/find an alg to balance the class vs not class for images (Cat vs Non-Cat)\n",
    "\n",
    "# possibly convert rgb images to grayscale using GLCM\n",
    "#      might want to compare rgb images and grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Confusion Matrix\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# cm = confusion_matrix([Y TEST DATA], [Y PREDICTIONS FROM MODEL], labels = [MODEL].classes_)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [MODEL].classes_)\n",
    "# disp.plot()\n",
    "# plt.show()\n",
    "\n",
    "#This is the code that I ran to obtain the Confusion Matrix for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isaiah Martinez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed dataset into model\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel = 'linear', cache_size = 2000, max_iter = 5000)\n",
    "clf.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###     Final Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joycelyn Tuazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
