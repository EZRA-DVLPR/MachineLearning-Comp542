\graphicspath{ {project_images/} }
\section{Related Works}

This section outlines the research done to find several algorithms that can be used to construct image classifiers.
Each of the following algorithms, except for CLIP, will be explained in more detail within the Methods section.

\subsection{SVM}
The first algorithm we looked at was Support Vector Machine (SVM) Classifier. 
Initial Research done showed that SVM outperformed Naive Bayes when perfoming image classification \cite{SVM}.
Through the use of Pipeline and Grid Search, we were able to find optimal performing parameters including: kernel, C, and gamma.
Grid Search allowed us to perform K-Fold cross validation on the model so that we would obtain more stable results.

\subsection{CNN}
Convolutional Neural Networks (CNN) were the main types of algorithms used by others looking into Image Classification.
This is because previous studies have shown the advantages to using such models to analyze and predict based on such complex datasets \cite{CNNPerformance}.
Additionally, there are various works using CNN models to perform varying types of Image Classification for several animals including primates, rodents, canines, felines, aves, and insecta \cite{AnimalSpecies1, AnimalSpecies2, AnimalBreed, Mosquito}.
When constructing our CNN models, we used the ReLu activation function for each hidden layer as well as the Adam optimizer since this seemed to be a common practice to improve performance.

\subsection{VGG16}
The VGG16 algorithm is available for use as a pre-trained model.
It was pre-trained to classify grayscale images of dogs and cats \cite{VGG16Greyscale}.
Upon discovery of how the model was trained, we decided to convert our images to grayscale.
VGG16 was pre-trained on a much larger data set than ours, and data augmentation methods were applied to our dataset as an approach to improving performance.
This seemed to be a straightforward attempt to increase the amount of data that the VGG16 model would see.

\subsection{CLIP}
As a last experimental algorithm, we also used a recently developed algorithm called Contrastive Language-Image Pre-training (CLIP) from OpenAI, the creators of prominent AI development technologies \cite{CLIP}.
This algorithm is a pre-trained model on images that are encoded, as well as associated text that has also been encoded to match the image.
The advantage of using CLIP was to experiment by using a novel technique called Zero-Shot Prediction (ZSP).
ZSP is the notion of encoding an image as well as a list of text that is the target feature, and having the pre-trained model perform a prediction based on no training from the desired dataset.
Because of the inability to change parameters and adjust the model, it will be excluded from the comparison to the other techniques.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{CLIP_structure}
	\caption{CLIP model summary}
	\label{fig:figure3}
\end{figure}

\subsection{Hypothesis}
Between the three animals, we expected to see Pandas being the most accurately predicted class since they are always black and white, and have high contrast compared to the surroundings.
This is especially true when compared to dogs and cats, which can come in a variety of colored fur.
Furthermore, we expected the Neural Network Algorithms as well as the pre-trained algorithms to perform faster and more accurately than SVM.